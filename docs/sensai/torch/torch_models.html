

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch_models &mdash; sensAI 0.0.5.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="torch_modules" href="torch_modules.html" />
    <link rel="prev" title="torch_data" href="torch_data.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> sensAI
          

          
          </a>

          
            
            
              <div class="version">
                0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Guides and Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Clustering%20Evaluation.html">Evaluating clustering algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Intro%20to%20Coordinate%20Clustering.html">The Coordinate Clustering Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Intro%20to%20sensAI.html">Lightning intro to sensAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Tracking%20Experiments.html">Tracking sensAI experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started.html">Getting started</a></li>
</ul>
<p class="caption"><span class="caption-text">Modules</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Modules</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../catboost.html">catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../clustering.html">clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../columngen.html">columngen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_ingest.html">data_ingest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data_transformation.html">data_transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../distance_metric.html">distance_metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ensemble.html">ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../evaluation.html">evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../featuregen.html">featuregen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../hyperopt.html">hyperopt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lightgbm.html">lightgbm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../local_search.html">local_search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../naive_bayes.html">naive_bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nearest_neighbors.html">nearest_neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../normalisation.html">normalisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sklearn.html">sklearn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensorflow.html">tensorflow</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../torch.html">torch</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="torch_base.html">torch_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch_data.html">torch_data</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">torch_models</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch_modules.html">torch_modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch_opt.html">torch_opt</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchtext.html">torchtext</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tracking.html">tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="../util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../vector_model.html">vector_model</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">sensAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Modules</a> &raquo;</li>
        
          <li><a href="../torch.html">torch</a> &raquo;</li>
        
      <li>torch_models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/sensai/torch/torch_models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="module-sensai.torch.torch_models">
<span id="torch-models"></span><h1>torch_models<a class="headerlink" href="#module-sensai.torch.torch_models" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronTorchModel">
<em class="property">class </em><code class="sig-name descname">MultiLayerPerceptronTorchModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cuda</span></em>, <em class="sig-param"><span class="n">hiddenDims</span></em>, <em class="sig-param"><span class="n">hidActivationFunction</span></em>, <em class="sig-param"><span class="n">outputActivationFunction</span></em>, <em class="sig-param"><span class="n">pDropout</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/jambit/sensAI/blob/master/src/sensai/torch/torch_models.py#L20"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronTorchModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_base.html#sensai.torch.torch_base.VectorTorchModel" title="sensai.torch.torch_base.VectorTorchModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sensai.torch.torch_base.VectorTorchModel</span></code></a></p>
<dl class="py method">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronTorchModel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cuda</span></em>, <em class="sig-param"><span class="n">hiddenDims</span></em>, <em class="sig-param"><span class="n">hidActivationFunction</span></em>, <em class="sig-param"><span class="n">outputActivationFunction</span></em>, <em class="sig-param"><span class="n">pDropout</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronTorchModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronTorchModel.createTorchModuleForDims">
<code class="sig-name descname">createTorchModuleForDims</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputDim</span></em>, <em class="sig-param"><span class="n">outputDim</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronTorchModel.createTorchModuleForDims" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronVectorRegressionModel">
<em class="property">class </em><code class="sig-name descname">MultiLayerPerceptronVectorRegressionModel</code><span class="sig-paren">(</span><em class="sig-param">hiddenDims=(5</em>, <em class="sig-param">5)</em>, <em class="sig-param">hidActivationFunction=torch.sigmoid</em>, <em class="sig-param">outputActivationFunction=None</em>, <em class="sig-param">normalisationMode=&lt;NormalisationMode.MAX_BY_COLUMN: 'max_by_column'&gt;</em>, <em class="sig-param">cuda=True</em>, <em class="sig-param">pDropout=None</em>, <em class="sig-param">**nnOptimiserParams</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/jambit/sensAI/blob/master/src/sensai/torch/torch_models.py#L37"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronVectorRegressionModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_base.html#sensai.torch.torch_base.TorchVectorRegressionModel" title="sensai.torch.torch_base.TorchVectorRegressionModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sensai.torch.torch_base.TorchVectorRegressionModel</span></code></a></p>
<dl class="py method">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronVectorRegressionModel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">hiddenDims=(5</em>, <em class="sig-param">5)</em>, <em class="sig-param">hidActivationFunction=torch.sigmoid</em>, <em class="sig-param">outputActivationFunction=None</em>, <em class="sig-param">normalisationMode=&lt;NormalisationMode.MAX_BY_COLUMN: 'max_by_column'&gt;</em>, <em class="sig-param">cuda=True</em>, <em class="sig-param">pDropout=None</em>, <em class="sig-param">**nnOptimiserParams</em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronVectorRegressionModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hiddenDims</strong> – sequence containing the number of neurons to use in hidden layers</p></li>
<li><p><strong>hidActivationFunction</strong> – the activation function (torch.*) to use for all hidden layers</p></li>
<li><p><strong>outputActivationFunction</strong> – the output activation function (torch.* or None)</p></li>
<li><p><strong>normalisationMode</strong> – the normalisation mode to apply to input and output data</p></li>
<li><p><strong>cuda</strong> – whether to use CUDA (GPU acceleration)</p></li>
<li><p><strong>pDropout</strong> – the probability with which to apply dropouts after each hidden layer</p></li>
<li><p><strong>nnOptimiserParams</strong> – parameters to pass on to NNOptimiser</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronVectorClassificationModel">
<em class="property">class </em><code class="sig-name descname">MultiLayerPerceptronVectorClassificationModel</code><span class="sig-paren">(</span><em class="sig-param">hiddenDims=(5</em>, <em class="sig-param">5)</em>, <em class="sig-param">hidActivationFunction=torch.sigmoid</em>, <em class="sig-param">outputActivationFunction=torch.sigmoid</em>, <em class="sig-param">normalisationMode=&lt;NormalisationMode.MAX_BY_COLUMN: 'max_by_column'&gt;</em>, <em class="sig-param">cuda=True</em>, <em class="sig-param">pDropout=None</em>, <em class="sig-param">**nnOptimiserParams</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/jambit/sensAI/blob/master/src/sensai/torch/torch_models.py#L54"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronVectorClassificationModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_base.html#sensai.torch.torch_base.TorchVectorClassificationModel" title="sensai.torch.torch_base.TorchVectorClassificationModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sensai.torch.torch_base.TorchVectorClassificationModel</span></code></a></p>
<dl class="py method">
<dt id="sensai.torch.torch_models.MultiLayerPerceptronVectorClassificationModel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param">hiddenDims=(5</em>, <em class="sig-param">5)</em>, <em class="sig-param">hidActivationFunction=torch.sigmoid</em>, <em class="sig-param">outputActivationFunction=torch.sigmoid</em>, <em class="sig-param">normalisationMode=&lt;NormalisationMode.MAX_BY_COLUMN: 'max_by_column'&gt;</em>, <em class="sig-param">cuda=True</em>, <em class="sig-param">pDropout=None</em>, <em class="sig-param">**nnOptimiserParams</em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.MultiLayerPerceptronVectorClassificationModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hiddenDims</strong> – sequence containing the number of neurons to use in hidden layers</p></li>
<li><p><strong>hidActivationFunction</strong> – the activation function (torch.*) to use for all hidden layers</p></li>
<li><p><strong>outputActivationFunction</strong> – the output activation function (torch.*)</p></li>
<li><p><strong>normalisationMode</strong> – the normalisation mode to apply to input and output data</p></li>
<li><p><strong>cuda</strong> – whether to use CUDA (GPU acceleration)</p></li>
<li><p><strong>pDropout</strong> – the probability with which to apply dropouts after each hidden layer</p></li>
<li><p><strong>nnOptimiserParams</strong> – parameters to pass on to NNOptimiser</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel">
<em class="property">class </em><code class="sig-name descname">LSTNetworkVectorClassificationModel</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">numInputTimeSlices</span></em>, <em class="sig-param"><span class="n">inputDimPerTimeSlice</span></em>, <em class="sig-param"><span class="n">numClasses</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numConvolutions</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">100</span></em>, <em class="sig-param"><span class="n">numCnnTimeSlices</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">6</span></em>, <em class="sig-param"><span class="n">hidRNN</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">100</span></em>, <em class="sig-param"><span class="n">skip</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">hidSkip</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em>, <em class="sig-param"><span class="n">hwWindow</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">hwCombine</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'plus'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">outputActivation</span><span class="o">=</span><span class="default_value">'sigmoid'</span></em>, <em class="sig-param"><span class="n">nnOptimiserParams</span><span class="p">:</span> <span class="n">dict</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/jambit/sensAI/blob/master/src/sensai/torch/torch_models.py#L71"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_base.html#sensai.torch.torch_base.TorchVectorClassificationModel" title="sensai.torch.torch_base.TorchVectorClassificationModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">sensai.torch.torch_base.TorchVectorClassificationModel</span></code></a></p>
<p>Classification model for time series data using the LSTNetwork architecture.</p>
<p>Since the model takes a time series as input, it requires that input data frames to use special naming of columns
such that the data can be interpreted correctly:
Each column name must start with an N-digit prefix indicating the time slice the data pertains to (for any fixed N);
the following suffix shall indicate the name of the actual feature.
For each N-digit prefix, we must have the same set of suffixes in the list of columns, i.e. we must have the same
features for each time slice in the input time series.</p>
<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">numInputTimeSlices</span></em>, <em class="sig-param"><span class="n">inputDimPerTimeSlice</span></em>, <em class="sig-param"><span class="n">numClasses</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>int<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">numConvolutions</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">100</span></em>, <em class="sig-param"><span class="n">numCnnTimeSlices</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">6</span></em>, <em class="sig-param"><span class="n">hidRNN</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">100</span></em>, <em class="sig-param"><span class="n">skip</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">hidSkip</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">5</span></em>, <em class="sig-param"><span class="n">hwWindow</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="default_value">0</span></em>, <em class="sig-param"><span class="n">hwCombine</span><span class="p">:</span> <span class="n">str</span> <span class="o">=</span> <span class="default_value">'plus'</span></em>, <em class="sig-param"><span class="n">dropout</span><span class="o">=</span><span class="default_value">0.2</span></em>, <em class="sig-param"><span class="n">outputActivation</span><span class="o">=</span><span class="default_value">'sigmoid'</span></em>, <em class="sig-param"><span class="n">nnOptimiserParams</span><span class="p">:</span> <span class="n">dict</span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>numInputTimeSlices</strong> – the number of input time slices</p></li>
<li><p><strong>inputDimPerTimeSlice</strong> – the dimension of the input data per time slice</p></li>
<li><p><strong>numClasses</strong> – the number of classes considered by this classification problem; if None, determine from data</p></li>
<li><p><strong>numCnnTimeSlices</strong> – the number of time slices considered by each convolution (i.e. it is one of the dimensions of the matrix used for
convolutions, the other dimension being inputDimPerTimeSlice), a.k.a. “Ck”</p></li>
<li><p><strong>numConvolutions</strong> – the number of separate convolutions to apply, i.e. the number of independent convolution matrices, a.k.a “hidC”;
if it is 0, then the entire complex processing path is not applied.</p></li>
<li><p><strong>hidRNN</strong> – the number of hidden output dimensions for the RNN stage</p></li>
<li><p><strong>skip</strong> – the number of time slices to skip for the skip-RNN. If it is 0, then the skip-RNN is not used.</p></li>
<li><p><strong>hidSkip</strong> – the number of output dimensions of each of the skip parallel RNNs</p></li>
<li><p><strong>hwWindow</strong> – the number of time slices from the end of the input time series to consider as input for the highway component.
If it is 0, the highway component is not used.</p></li>
<li><p><strong>hwCombine</strong> – {“plus”, “product”, “bilinear”} the function with which the highway component’s output is combined with the complex path’s output</p></li>
<li><p><strong>dropout</strong> – the dropout probability to use during training (dropouts are applied after every major step in the evaluation path)</p></li>
<li><p><strong>outputActivation</strong> – the output activation function</p></li>
<li><p><strong>nnOptimiserParams</strong> – parameters of NNOptimiser to use for training</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil">
<em class="property">class </em><code class="sig-name descname">DataUtil</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_data</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">y_data</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">numClasses</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="torch_data.html#sensai.torch.torch_data.DataUtil" title="sensai.torch.torch_data.DataUtil"><code class="xref py py-class docutils literal notranslate"><span class="pre">sensai.torch.torch_data.DataUtil</span></code></a></p>
<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x_data</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">y_data</span><span class="p">:</span> <span class="n">pandas.core.frame.DataFrame</span></em>, <em class="sig-param"><span class="n">numClasses</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize self.  See help(type(self)) for accurate signature.</p>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.inputDim">
<code class="sig-name descname">inputDim</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.inputDim" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the dimensionality of the input or None if it is variable</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.modelOutputDim">
<code class="sig-name descname">modelOutputDim</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.modelOutputDim" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the dimensionality that is to be output by the model to be trained</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.splitInputOutputPairs">
<code class="sig-name descname">splitInputOutputPairs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fractionalSizeOfFirstSet</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.splitInputOutputPairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the data set</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fractionalSizeOfFirstSet</strong> – the desired fractional size in</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tuple (A, B) where A and B are tuples (in, out) with input and output data</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getInputOutputPair">
<code class="sig-name descname">getInputOutputPair</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">output</span></em>, <em class="sig-param"><span class="n">input</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getInputOutputPair" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getOutputTensorScaler">
<code class="sig-name descname">getOutputTensorScaler</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="torch_data.html#sensai.torch.torch_data.TensorScaler" title="sensai.torch.torch_data.TensorScaler">sensai.torch.torch_data.TensorScaler</a><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getOutputTensorScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the scaler with which to scale model outputs</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the scaler</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getInputTensorScaler">
<code class="sig-name descname">getInputTensorScaler</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="torch_data.html#sensai.torch.torch_data.TensorScaler" title="sensai.torch.torch_data.TensorScaler">sensai.torch.torch_data.TensorScaler</a><a class="headerlink" href="#sensai.torch.torch_models.LSTNetworkVectorClassificationModel.DataUtil.getInputTensorScaler" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the scaler with which to scale model inputs</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the scaler</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="torch_modules.html" class="btn btn-neutral float-right" title="torch_modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="torch_data.html" class="btn btn-neutral float-left" title="torch_data" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>